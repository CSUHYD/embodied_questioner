from ai2thor.controller import Controller
import random
import math
import re
import time
import threading
import copy
from PIL import Image
import sys
import os
# from vlmCall import 
from vlmCall_ollama import VLMAPI
from utils import save_data_to_json,save_image,clear_folder,load_json,get_volume_distance_rate

from baseAction import BaseAction
from RocAgent import RocAgent       
import json
import functools
import logging


def load_prompt_config(config_path="config/prompt_config.json"):
    """åŠ è½½ prompt é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Warning: Config file {config_path} not found, using default config")
        return 

def load_scene_config(config_path="config/scene_config.json"):
    """åŠ è½½åœºæ™¯é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Warning: Scene config file {config_path} not found, using default config")
        return {}

# é»˜è®¤é…ç½®
PROMPT_CONFIG = load_prompt_config()
SCENE_CONFIG = load_scene_config()


class SceneManager:
    def __init__(self, timeout=40, scene_config=None):
        self.timeout = timeout
        self.scene_config = scene_config or SCENE_CONFIG
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½åœºæ™¯é…ç½®
        self.scene_configs = self.scene_config.get("scene_configs", {})
        self.room_configs = self.scene_config.get("room_configs", {})
        self.controller_config = self.scene_config.get("controller_config", {})

    def get_scene_paths(self, env, room, scene, tasktype):
        """ç”Ÿæˆåœºæ™¯ç›¸å…³çš„è·¯å¾„"""
        metadata_path = f"data_engine/{env}/{room}/{scene}/metadata.json"
        origin_pos_path = f"data_engine/{env}/{room}/{scene}/originPos.json"
        generate_task = f"data_engine/{tasktype}_task_metadata/{scene}.json"
        
        return {
            'metadata_path': metadata_path,
            'origin_pos_path': origin_pos_path,
            'generate_task': generate_task
        }

    def get_floorplans_by_room(self, room):
        """æ ¹æ®æˆ¿é—´ç±»å‹è·å–å¯¹åº”çš„æ¥¼å±‚å¹³é¢å›¾åˆ—è¡¨"""
        if room not in self.room_configs:
            return []
            
        room_config = self.room_configs[room]
        floorplans = room_config.get("floorplans", [])
        
        # ç”ŸæˆFloorPlanåç§°
        if room == 'kitchens':
            return [f"FloorPlan{i}" for i in floorplans]
        elif room == 'living_rooms':
            return [f"FloorPlan{i}" for i in floorplans]
        elif room == 'bedrooms':
            return [f"FloorPlan{i}" for i in floorplans]
        elif room == 'bathrooms':
            return [f"FloorPlan{i}" for i in floorplans]
        else:
            return []

    def calculate_scene_diagonal(self, metadata):
        """è®¡ç®—åœºæ™¯å¯¹è§’çº¿è·ç¦»"""
        scene_size = metadata["sceneBounds"]["size"]
        return math.sqrt(scene_size["x"]**2 + scene_size["z"]**2)

    def initialize_scene(self, scene_diagonal, origin_pos_path, scene):
        """åˆå§‹åŒ–åœºæ™¯"""
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ§åˆ¶å™¨é…ç½®
        controller = Controller( 
            agentMode=self.controller_config.get("agentMode", "default"),
            visibilityDistance=scene_diagonal, 
            scene=scene,
            gridSize=self.controller_config.get("gridSize", 0.1),
            snapToGrid=self.controller_config.get("snapToGrid", True),
            rotateStepDegrees=self.controller_config.get("rotateStepDegrees", 90),
            renderDepthImage=self.controller_config.get("renderDepthImage", False),
            renderInstanceSegmentation=self.controller_config.get("renderInstanceSegmentation", False),
            width=self.controller_config.get("width", 1600),
            height=self.controller_config.get("height", 900),
            fieldOfView=self.controller_config.get("fieldOfView", 90),
        )
        
        # è®¾ç½®åˆå§‹ä½ç½®ï¼ˆé™¤äº†FloorPlan22ï¼‰
        if scene != 'FloorPlan22':
            pos = load_json(origin_pos_path)
            position = pos["position"]
            rotation = pos["rotation"]  
            horizon = pos["cameraHorizon"]   
            
            controller.step(
                action="Teleport",
                position=position,
                rotation=rotation,
                horizon=horizon,
                standing=True
            )
        
        # æ‰§è¡Œåœºæ™¯ç‰¹å®šçš„åˆå§‹åŒ–åŠ¨ä½œ
        self._execute_scene_specific_actions(controller, scene)
        
        metadata = controller.last_event.metadata
        return controller, metadata

    def _execute_scene_specific_actions(self, controller, scene):
        """æ‰§è¡Œåœºæ™¯ç‰¹å®šçš„åˆå§‹åŒ–åŠ¨ä½œ"""
        if scene in self.scene_configs:
            for action_config in self.scene_configs[scene]:
                action = action_config["action"]
                if "moveMagnitude" in action_config:
                    controller.step(action=action, moveMagnitude=action_config["moveMagnitude"])
                elif "degrees" in action_config:
                    controller.step(action=action, degrees=action_config["degrees"])

    def run_initial_scene(self, scene_diagonal, origin_pos_path, scene, retry_limit=3):
        """è¿è¡Œåœºæ™¯åˆå§‹åŒ–ï¼Œæ”¯æŒè¶…æ—¶å’Œé‡è¯•"""
        controller = None
        metadata = None
        retry_count = 0

        def init_task():
            nonlocal controller
            nonlocal metadata
            controller, metadata = self.initialize_scene(scene_diagonal, origin_pos_path, scene) 
            
        init_thread = threading.Thread(target=init_task)
        init_thread.start()
        init_thread.join(self.timeout) 

        if init_thread.is_alive():
            print(f"Initialization exceeded {self.timeout} seconds, retrying...")
            retry_count += 1
            controller, metadata = self.initialize_scene(scene_diagonal, origin_pos_path, scene)
            return controller, metadata
        else:
            print("Initialization succeeded") 
            return controller, metadata

    def load_scene_metadata(self, metadata_path):
        """åŠ è½½åœºæ™¯å…ƒæ•°æ®"""
        metadata = load_json(metadata_path)
        return metadata[0] if metadata else None

    def load_scene_tasks(self, generate_task):
        """åŠ è½½åœºæ™¯ä»»åŠ¡"""
        tasks = load_json(generate_task)
        return tasks[0] if tasks else []



class TaskPlanner:
    def __init__(self, model, config=None):
        self.model = model
        self.config = config or PROMPT_CONFIG
        self.subgoals = []  # å½“å‰é«˜å±‚å­ç›®æ ‡

    def plan_high_level_subgoals(self, taskname, environment_description, memory_text=None):
        """
        è°ƒç”¨ high_level_task_planning promptï¼Œè¾“å‡ºé«˜å±‚å­ç›®æ ‡ <SubgoalN> æ ‡ç­¾
        """
        systext = self.config["high_level_task_planning"]["systext"]
        history_info = ""
        if memory_text:
            history_info = f"History:\n{memory_text}\n"
        usertext = self.config["high_level_task_planning"]["usertext"].format(
            history_info=history_info,
            taskname=taskname,
            environment_description=environment_description
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        # è§£æ <SubgoalN> æ ‡ç­¾ï¼Œæ”¯æŒâ€œå­ç›®æ ‡: æè¿°â€æ ¼å¼
        import re
        subgoal_pattern = r'<Subgoal\d+>(.*?)</Subgoal\d+>'
        matches = re.findall(subgoal_pattern, result, re.DOTALL)
        subgoals = [m.strip() for m in matches]
        self.subgoals = subgoals
        return subgoals

    def plan_executable_subtasks(self, subgoal, context=None):
        """
        è°ƒç”¨ executable_task_planning promptï¼Œå°†é«˜å±‚å­ç›®æ ‡ç»†åŒ–ä¸ºå¯æ‰§è¡ŒåŠ¨ä½œåºåˆ— <SubtaskN> æ ‡ç­¾
        """
        systext = self.config["executable_task_planning"]["systext"]
        usertext = self.config["executable_task_planning"]["usertext"].format(
            subgoal=subgoal,
            context=context or ""
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        # è§£æ <SubtaskN> æ ‡ç­¾
        import re
        subtask_pattern = r'<Subtask(\d+)>\s*\[(.*?)\]\s*\[(.*?)\]\s*</Subtask\1>'
        matches = re.findall(subtask_pattern, result, re.DOTALL)
        subtasks = []
        for match in matches:
            subtask_num, action, objtype = match
            subtasks.append({
                "subtask_id": int(subtask_num),
                "action": action.strip(),
                "objectId": "",
                "objectType": objtype.strip()
            })
        return subtasks

    def replan_based_on_user_response(self, taskname, observation, question, response, subgoal):
        """
        æ ¹æ®ç”¨æˆ·å›ç­”ç”Ÿæˆæ–°çš„planï¼ˆsubgoalsï¼‰ã€‚
        """
        prompt_cfg = self.config.get("replan_by_user_response")
        systext = prompt_cfg["systext"]
        usertext = prompt_cfg["usertext"]
        usertext = usertext.format(
            taskname=taskname,
            observation=observation or "",
            question=question or "",
            response=response or "",
            subgoal=subgoal or ""
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        # å¤ç”¨é«˜å±‚subgoalçš„æ­£åˆ™è§£æ
        import re
        subgoal_pattern = r'<Subgoal\d+>(.*?)</Subgoal\d+>'
        matches = re.findall(subgoal_pattern, result, re.DOTALL)
        subgoals = [m.strip() for m in matches]
        self.subgoals = subgoals  # æ›´æ–°æˆå‘˜å˜é‡
        return subgoals


class ObservationGenerator:
    def __init__(self, model, config=None):
        self.model = model
        self.config = config or PROMPT_CONFIG

    def generate_observation(self, image_path, navigable_list=None):
        # å€Ÿé‰´ o1StyleGenerateï¼ŒObservation åªéœ€ç®€è¦æè¿°å¯è§ç‰©ä½“ï¼Œä¸éœ€è¦ç‰©ä½“å…³ç³»ï¼Œè¾“å‡º <Observation>...</Observation>
        # è·å–å¯è§ç±»åˆ«
        navigable_categories = []
        if navigable_list:
            navigable_categories = list(set([item["objectType"] for item in navigable_list]))
        systext = self.config["observation"]["systext"]
        usertext = self.config["observation"].get("usertext", "").format(navigable_categories=navigable_categories)
        llmapi = VLMAPI(self.model)
        observation = llmapi.vlm_request(systext, usertext, image_path)
        return observation

    def save_initial_observation_image(self, controller, origin_path):
        event = controller.last_event
        init_image_path = f"{origin_path}/0_init_observe.png"
        os.makedirs(os.path.dirname(init_image_path), exist_ok=True)
        save_image(event, init_image_path)
        return init_image_path

class QuestionGenerator:
    def __init__(self, model, config=None):
        self.model = model
        self.config = config or PROMPT_CONFIG

    def generate_general_question_for_plan(self, taskname, subgoals, observation=None):
        """
        é’ˆå¯¹åˆå§‹ä»»åŠ¡è§„åˆ’ï¼ˆsubgoalsï¼‰å’Œobservationï¼Œè‡ªåŠ¨æå‡ºä¸€ä¸ªgeneralç±»å‹çš„é—®é¢˜ã€‚
        """
        prompt_cfg = self.config.get("general_plan_question")
        systext = prompt_cfg["systext"]
        usertext = prompt_cfg["usertext"]
        subgoals_str = "\n".join([f"- {g}" for g in subgoals])
        usertext = usertext.format(taskname=taskname, subgoals=subgoals_str, observation=observation or "")
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        import re
        m = re.search(r'QUESTION:\s*(.*)', result)
        question = m.group(1).strip() if m else result.strip()
        return question

    # def should_ask_question_vlm(self, taskname, observation=None, planning=None, memory_text=None, navigable_list=None, error_message=None):
    #     """
    #     ç”±VLMåˆ¤æ–­æ˜¯å¦éœ€è¦æé—®ï¼Œå¹¶è¿”å›(should_ask, type, question)
    #     """
    #     import re
    #     prompt_cfg = self.config["question_judge"]
    #     systext = prompt_cfg["systext"]
    #     # ç›´æ¥å°†å˜é‡æ˜¾å¼è¾“å…¥
    #     navigable_str = ""
    #     if navigable_list:
    #         types = list(set([item["objectType"] for item in navigable_list]))
    #         navigable_str = ", ".join(types)
    #     usertext = prompt_cfg["usertext"].format(
    #         taskname=taskname,
    #         observation=observation or "",
    #         planning=planning or "",
    #         memory_text=memory_text or "",
    #         navigable_str=navigable_str,
    #         error_message=error_message or ""
    #     )
    #     llmapi = VLMAPI(self.model)
    #     result = llmapi.vlm_request(systext, usertext)
    #     ask = re.search(r'ASK:\s*(yes|no)', result, re.IGNORECASE)
    #     qtype = re.search(r'TYPE:\s*(clarification|help|general)', result, re.IGNORECASE)
    #     question = re.search(r'QUESTION:\s*(.*)', result)
    #     should_ask = ask and ask.group(1).strip().lower() == "yes"
    #     question_type = qtype.group(1).strip().lower() if qtype else "general"
    #     question_text = question.group(1).strip() if question else ""
    #     return should_ask, question_type, question_text


class UserResponseHandler:
    def __init__(self, model, taskname, plan, memory, config=None):
        self.model = model
        self.taskname = taskname
        self.plan = plan
        self.memory = memory
        self.config = config or PROMPT_CONFIG

    def init_response(self, user_response):
        """
        ç»¼åˆå½“å‰taskã€è§„åˆ’ã€é—®ç­”å†å²å’Œç”¨æˆ·å›ç­”ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦replanã€‚
        è¿”å› (need_replan: bool, reason: str)
        """
        # è¿™é‡Œå¯ä»¥ç”¨LLMåˆ¤æ–­ï¼Œä¹Ÿå¯ä»¥ç”¨è§„åˆ™ã€‚å…ˆç»™å‡ºLLM promptæ–¹æ¡ˆï¼š
        prompt_cfg = self.config.get("user_response_replan_judge")
        systext = prompt_cfg["systext"]
        usertext = prompt_cfg["usertext"]

        plan_str = "\n".join([str(p) for p in self.plan]) if isinstance(self.plan, list) else str(self.plan)
        memory_str = "\n".join([m["content"] if isinstance(m, dict) and "content" in m else str(m) for m in self.memory]) if isinstance(self.memory, list) else str(self.memory)
        usertext = usertext.format(
            taskname=self.taskname,
            plan=plan_str,
            memory=memory_str,
            user_response=user_response
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        import re
        m = re.search(r'REPLAN:\s*(yes|no)', result, re.IGNORECASE)
        reason_m = re.search(r'REASON:\s*(.*)', result)
        need_replan = m and m.group(1).strip().lower() == "yes"
        reason = reason_m.group(1).strip() if reason_m else result.strip()
        return need_replan, reason

    def get_user_response(self, question):
        """æ¨¡æ‹Ÿæˆ–å®é™…è·å–ç”¨æˆ·å›ç­”ã€‚å®é™…éƒ¨ç½²æ—¶å¯æ›¿æ¢ä¸ºinput()æˆ–UIäº¤äº’ã€‚"""
        user_response = input("ğŸ˜ï¼šè¯·è¾“å…¥ä½ çš„å›ç­”ï¼š")
        # è¿™é‡Œå¯æ›¿æ¢ä¸ºå®é™…äº¤äº’
        return user_response


class RobotController:
    def __init__(self, controller, metadata, model, origin_path, config=None):
        self.memory = []  # é•¿æœŸè®°å¿†
        self.controller = controller
        self.metadata = metadata
        self.model = model
        self.origin_path = origin_path
        self.observation_generator = ObservationGenerator(model, config)
        self.task_planner = TaskPlanner(model, config)
        self.question_generator = QuestionGenerator(model, config)
        self.user_response_handler = UserResponseHandler(model, None, None, self.memory, config)
        # æ·»åŠ navigable_listç›¸å…³å±æ€§
        self.navigable_list = []
        self.round = 1
        self.his_objects_list = []
        # æ·»åŠ æé—®ç›¸å…³å±æ€§
        self.failed_attempts = 0
        self.last_question = None


    def add_memory(self, entry, memory_type):
        """
        å­˜å‚¨è®°å¿†å†…å®¹ï¼Œmemory_typeä¸ºç±»åˆ«ï¼ˆå¦‚'planning'ã€'question'ã€'answer'ç­‰ï¼‰ï¼Œentryä¸ºå†…å®¹ã€‚
        """
        self.memory.append({"type": memory_type, "content": entry})

    def get_memory_text(self, max_steps=10, type_filter=None):
        """
        è¿”å›æœ€è¿‘çš„max_stepsæ¡è®°å¿†å†…å®¹ï¼Œå¯é€‰æŒ‰typeè¿‡æ»¤ã€‚
        """
        if type_filter:
            filtered = [m["content"] for m in self.memory if m["type"] == type_filter]
            return "\n".join(filtered[-max_steps:])
        else:
            return "\n".join(m["content"] for m in self.memory[-max_steps:])

    def initial_navigable_list(self):
        """åˆå§‹åŒ–å¯å¯¼èˆªå¯¹è±¡åˆ—è¡¨"""
        self.metadata = self.controller.last_event.metadata
        list_obj = get_volume_distance_rate(self.metadata)
        for item in list_obj:
            if item["isnavigable"] and item["objectType"] != "Floor":
                objectType = item["objectType"]
                objectId = item["objectId"]
                visibleTimes = 1
                choseTimes = 0
                obj_navigable = {
                    "objectType": objectType,
                    "objectId": objectId,
                    "visibleTimes": visibleTimes,
                    "choseTimes": choseTimes
                }
                self.navigable_list.append(obj_navigable)
        return self.navigable_list

    def update_navigable_list_vtime(self):
        """æ›´æ–°å¯å¯¼èˆªå¯¹è±¡åˆ—è¡¨çš„å¯è§æ¬¡æ•°"""
        self.metadata = self.controller.last_event.metadata
        list_obj = get_volume_distance_rate(self.metadata)
        for item in list_obj:
            if item["isnavigable"]:
                found = False
                for last_item in self.navigable_list:
                    if last_item["objectId"] == item["objectId"]:
                        last_item["visibleTimes"] += 1
                        found = True
                        break
                    
                if not found:
                    new_item = {
                        "objectType": item["objectType"],
                        "objectId": item["objectId"],
                        "visibleTimes": 1,
                        "choseTimes": 0
                    }
                    self.navigable_list.append(new_item)
        return self.navigable_list

    def get_object_types_from_navigable_list(self):
        """ä»å¯å¯¼èˆªåˆ—è¡¨ä¸­è·å–å¯¹è±¡ç±»å‹"""
        object_types = [item['objectType'] for item in self.navigable_list]
        unique_object_types = list(set(object_types))
        return unique_object_types

    def update(self):
        """æ›´æ–°æ§åˆ¶å™¨çŠ¶æ€"""
        self.metadata = self.controller.last_event.metadata
        self.navigable_list = self.update_navigable_list_vtime()

    def generate_observation(self, image_path):
        # ä¼ é€’ navigable_list ä»¥ä¾¿ Observation åªæè¿°å¯å¯¼èˆªç±»åˆ«
        # åˆå§‹åŒ–å¯å¯¼èˆªåˆ—è¡¨
        self.navigable_list = self.initial_navigable_list()
        obs = self.observation_generator.generate_observation(image_path, self.navigable_list)
        return obs

    def plan_high_level_task(self, taskname, environment_description, memory_text=None):
        """é¦–æ¬¡ä»»åŠ¡è§„åˆ’ï¼šå°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œä¸ä½¿ç”¨memory"""
        subgoals = self.task_planner.plan_high_level_subgoals(
            taskname, environment_description, memory_text=memory_text
        )
        self.add_memory(f"Initial Task Planning: {subgoals}", "planning")
        return subgoals

    def get_navigable_list(self):
        """è·å–å¯å¯¼èˆªåˆ—è¡¨"""
        return self.navigable_list

    def receive_user_response(self, response):
        """æ¥æ”¶ç”¨æˆ·å›ç­”"""
        logging.info("[ROBOT QUESTION] %s. User Response: %s.", self.last_question, response)

    def ask_general_question_for_plan(self, taskname, subgoals, observation=None):
        """
        é’ˆå¯¹åˆå§‹ä»»åŠ¡è§„åˆ’å’Œobservationï¼Œè‡ªåŠ¨æå‡ºgeneralç±»å‹çš„é—®é¢˜å¹¶å­˜å…¥memoryã€‚
        """
        question = self.question_generator.generate_general_question_for_plan(taskname, subgoals, observation=observation)
        self.last_question = question
        self.add_memory(f"General Question: {question}", "question")
        logging.info("[GENERAL QUESTION] %s", question)
        return question

    def set_user_response_handler_context(self, taskname, plan):
        self.user_response_handler.taskname = taskname
        self.user_response_handler.plan = plan
        self.user_response_handler.memory = self.memory


if __name__=="__main__":
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.StreamHandler()]
    )
    env="taskgenerate"
    model = "qwen2.5vl:32b" # use gpt-4o to generate trajectories
    # you can set timeout for AI2THOR init here.        

    ###### step1. choose the task type here ####################
    tasktype="pickup_and_put"
    room_type = ['kitchens','living_rooms','bedrooms','bathrooms']
    room = 'kitchens'
    scene = 'FloorPlan3'
    
    # åˆ›å»ºåœºæ™¯ç®¡ç†å™¨
    scene_manager = SceneManager()
    
    # è·å–åœºæ™¯ç›¸å…³è·¯å¾„
    paths = scene_manager.get_scene_paths(env, room, scene, tasktype)
    metadata_path = paths['metadata_path']
    origin_pos_path = paths['origin_pos_path']
    generate_task = paths['generate_task']
    
    logging.info("metadata_path: %s", metadata_path)
    logging.info("task_metadata_path: %s", generate_task)
    
    # åŠ è½½åœºæ™¯å…ƒæ•°æ®å’Œä»»åŠ¡
    metadata = scene_manager.load_scene_metadata(metadata_path)
    tasks = scene_manager.load_scene_tasks(generate_task)

    for instruction_idx, task in enumerate(tasks, start=0):                                                            
        logging.info("\n\n*********************************************************************")
        logging.info(f"Scene:{scene} Task_Type: {tasktype} Processing_Task: {instruction_idx}")
        logging.info("*********************************************************************\n")

        task=tasks[instruction_idx]
        logging.info("task: %s", task)
        
        start_time = time.time()
        origin_path=f"data/data_{task['tasktype']}/{scene}_{task['tasktype']}_{instruction_idx}"
        
        # è®¡ç®—åœºæ™¯å¯¹è§’çº¿è·ç¦»
        scene_diagonal = scene_manager.calculate_scene_diagonal(metadata)
        
        max_retries=2
        error_paths = []  
        for attempt in range(max_retries + 1): 
            try:
                # ä½¿ç”¨åœºæ™¯ç®¡ç†å™¨åˆå§‹åŒ–åœºæ™¯
                controller, metadata = scene_manager.run_initial_scene(scene_diagonal, origin_pos_path, scene)

                # å°è£…åçš„æœºå™¨äººæ§åˆ¶å™¨
                robot_controller = RobotController(controller, metadata, model, origin_path)
                
                # æ­¥éª¤1ï¼šä¿å­˜åˆå§‹è§‚å¯Ÿå›¾ç‰‡
                init_image_path = robot_controller.observation_generator.save_initial_observation_image(robot_controller.controller, robot_controller.origin_path)
                
                # æ­¥éª¤2ï¼šç”Ÿæˆobservation
                observation = robot_controller.generate_observation(init_image_path)
                logging.info("[OBSERVATION] %s", observation)
                
                # æ­¥éª¤3ï¼šä»»åŠ¡è§„åˆ’ï¼ˆåªç”¨é«˜å±‚tasknameå’Œobservationï¼‰
                taskname = task["taskname"]  # ä¾‹å¦‚ "æŠŠè‹¹æœæ”¾è¿›å†°ç®±"
                subgoals = robot_controller.plan_high_level_task(taskname, observation)
                logging.info("[INITIAL TASK PLANNING] %s", str(subgoals))
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æé—®
                question = robot_controller.ask_general_question_for_plan(taskname, subgoals)
                
                if question:
                    robot_controller.set_user_response_handler_context(taskname, subgoals)
                    # è·å–ç”¨æˆ·å›ç­”
                    user_response = robot_controller.user_response_handler.get_user_response(question)
                    robot_controller.receive_user_response(user_response)

                    logging.info("[RE-PLANNING BASED ON USER RESPONSE]")
                    # å…ˆåˆ¤æ–­æ˜¯å¦éœ€è¦replan
                    need_replan, reason = robot_controller.user_response_handler.init_response(user_response)
                    if need_replan:
                        old_subgoals = robot_controller.task_planner.subgoals
                        new_subgoals = robot_controller.task_planner.replan_based_on_user_response(
                            taskname, observation, robot_controller.last_question, user_response, subgoals
                        )
                        new_subgoals = robot_controller.task_planner.subgoals
                        logging.info("[REPLAN] Old subgoals: %s", old_subgoals)
                        logging.info("[REPLAN] New subgoals: %s", new_subgoals)
                        logging.info("[RE-PLANNED TASK] %s", str(new_subgoals))
                        robot_controller.add_memory(f"{new_subgoals}", "planning")
                        # ä½ å¯ä»¥åœ¨æ­¤å¤„ç»§ç»­åç»­æ‰§è¡Œæ–°è§„åˆ’çš„é€»è¾‘
                    else:
                        logging.info("[NO REPLAN NEEDED] Reason: %s", reason)

                # æ­¥éª¤4ï¼šè·å–å¯å¯¼èˆªå¯¹è±¡ç±»å‹ï¼ˆç”¨äºåç»­è§„åˆ’ï¼‰
                navigable_types = robot_controller.get_object_types_from_navigable_list()
                logging.info("[NAVIGABLE TYPES] %s", navigable_types)
                
                # æ­¥éª¤5ï¼šæ›´æ–°å¯å¯¼èˆªåˆ—è¡¨
                robot_controller.update()
                updated_navigable_list = robot_controller.get_navigable_list()
                logging.info("[UPDATED NAVIGABLE LIST] %d objects", len(updated_navigable_list))
                
                # åç»­æ­¥éª¤ï¼šå¾ªç¯æ‰§è¡Œå­ä»»åŠ¡
                # for subtask in subtasks:
                #     print("æ‰§è¡Œå­ä»»åŠ¡:", subtask)
                #     # è¿™é‡Œå¯ä»¥æ ¹æ®subtask["action"]å’Œ["objectType"]ç­‰ï¼Œè°ƒç”¨åº•å±‚æ§åˆ¶API
                #     # æ¯æ­¥å¯è§‚æµ‹ã€å¯replan
                #     # ä¼ªä»£ç ï¼š
                #     # result = robot_controller.execute_subtask(subtask)
                #     # if result == "need_replan":
                #     #     observation = robot_controller.generate_observation(...)
                #     #     subtasks = robot_controller.plan_task(taskname, observation)
                #     #     break
                
                # o1stylegenerate=O1StyleGenerate(
                #     controller,scene,origin_path,metadata,task,model=model
                # )
                # o1stylegenerate.initial_navigable_list()
                
                # # json_path=f"{origin_path}/metadata/0_metadata.json"
                # # o1stylegenerate.generate_o1style_data["round_metadata"].append(json_path)
                # # save_data_to_json(o1stylegenerate.metadata,json_path)
                # # o1stylegenerate.generate_o1style_data["round_navigable_list"].append(o1stylegenerate.navigable_list)

                
                # o1stylegenerate.generate_o1style_data["task_metadata"]=task
                
                # o1stylegenerate.generate_o1style_data["scene"]=scene
                # o1stylegenerate.generate_o1style_data["tasktype"]=tasktype 
                # o1stylegenerate.generate_o1style_data["instruction_idx"]=instruction_idx
                
                # o1stylegenerate.generate_one_o1style_data(plan_num,correct_num)
                
                # end_time = time.time()

                # execution_time = end_time - start_time
                # print(f"Execution time: {execution_time:.4f} seconds") 
                
                # o1stylegenerate.generate_o1style_data["time"]=execution_time

                # path=f"{origin_path}/{scene}_{task['tasktype']}_{instruction_idx}_{trajectory_idx}.json"
                
                # save_data_to_json(o1stylegenerate.generate_o1style_data,path)
                # print("generate_o1style_data save:",{path})
                
                # controller.stop()
                # break

            except Exception as e:
                logging.error("[ERROR] %s, try again.", e)
                clear_folder(origin_path)
            
                if attempt == max_retries - 1: 
                    logging.warning("[RETRY %d TIMES, JUMP THE TASK]", max_retries)
                    error_paths.append(origin_path)  
                    save_data_to_json(error_paths,"./wrong_generte_path_list.json")
                    continue
