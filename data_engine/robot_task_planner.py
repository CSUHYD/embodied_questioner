from ai2thor.controller import Controller
import random
import math
import re
import time
import threading
import copy
from PIL import Image
import sys
import os
# from vlmCall import 
from vlmCall_ollama import VLMAPI
from utils import save_data_to_json,save_image,clear_folder,load_json,get_volume_distance_rate

from baseAction import BaseAction
from RocAgent import RocAgent       
import json

def load_prompt_config(config_path="config/prompt_config.json"):
    """åŠ è½½ prompt é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Warning: Config file {config_path} not found, using default config")
        return 

def load_scene_config(config_path="config/scene_config.json"):
    """åŠ è½½åœºæ™¯é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Warning: Scene config file {config_path} not found, using default config")
        return {}

# é»˜è®¤é…ç½®
PROMPT_CONFIG = load_prompt_config()
SCENE_CONFIG = load_scene_config()


class SceneManager:
    def __init__(self, timeout=40, scene_config=None):
        self.timeout = timeout
        self.scene_config = scene_config or SCENE_CONFIG
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½åœºæ™¯é…ç½®
        self.scene_configs = self.scene_config.get("scene_configs", {})
        self.room_configs = self.scene_config.get("room_configs", {})
        self.controller_config = self.scene_config.get("controller_config", {})

    def get_scene_paths(self, env, room, scene, tasktype):
        """ç”Ÿæˆåœºæ™¯ç›¸å…³çš„è·¯å¾„"""
        metadata_path = f"data_engine/{env}/{room}/{scene}/metadata.json"
        origin_pos_path = f"data_engine/{env}/{room}/{scene}/originPos.json"
        generate_task = f"data_engine/{tasktype}_task_metadata/{scene}.json"
        
        return {
            'metadata_path': metadata_path,
            'origin_pos_path': origin_pos_path,
            'generate_task': generate_task
        }

    def get_floorplans_by_room(self, room):
        """æ ¹æ®æˆ¿é—´ç±»å‹è·å–å¯¹åº”çš„æ¥¼å±‚å¹³é¢å›¾åˆ—è¡¨"""
        if room not in self.room_configs:
            return []
            
        room_config = self.room_configs[room]
        floorplans = room_config.get("floorplans", [])
        
        # ç”ŸæˆFloorPlanåç§°
        if room == 'kitchens':
            return [f"FloorPlan{i}" for i in floorplans]
        elif room == 'living_rooms':
            return [f"FloorPlan{i}" for i in floorplans]
        elif room == 'bedrooms':
            return [f"FloorPlan{i}" for i in floorplans]
        elif room == 'bathrooms':
            return [f"FloorPlan{i}" for i in floorplans]
        else:
            return []

    def calculate_scene_diagonal(self, metadata):
        """è®¡ç®—åœºæ™¯å¯¹è§’çº¿è·ç¦»"""
        scene_size = metadata["sceneBounds"]["size"]
        return math.sqrt(scene_size["x"]**2 + scene_size["z"]**2)

    def initialize_scene(self, scene_diagonal, origin_pos_path, scene):
        """åˆå§‹åŒ–åœºæ™¯"""
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ§åˆ¶å™¨é…ç½®
        controller = Controller( 
            agentMode=self.controller_config.get("agentMode", "default"),
            visibilityDistance=scene_diagonal, 
            scene=scene,
            gridSize=self.controller_config.get("gridSize", 0.1),
            snapToGrid=self.controller_config.get("snapToGrid", True),
            rotateStepDegrees=self.controller_config.get("rotateStepDegrees", 90),
            renderDepthImage=self.controller_config.get("renderDepthImage", False),
            renderInstanceSegmentation=self.controller_config.get("renderInstanceSegmentation", False),
            width=self.controller_config.get("width", 1600),
            height=self.controller_config.get("height", 900),
            fieldOfView=self.controller_config.get("fieldOfView", 90),
        )
        
        # è®¾ç½®åˆå§‹ä½ç½®ï¼ˆé™¤äº†FloorPlan22ï¼‰
        if scene != 'FloorPlan22':
            pos = load_json(origin_pos_path)
            position = pos["position"]
            rotation = pos["rotation"]  
            horizon = pos["cameraHorizon"]   
            
            controller.step(
                action="Teleport",
                position=position,
                rotation=rotation,
                horizon=horizon,
                standing=True
            )
        
        # æ‰§è¡Œåœºæ™¯ç‰¹å®šçš„åˆå§‹åŒ–åŠ¨ä½œ
        self._execute_scene_specific_actions(controller, scene)
        
        metadata = controller.last_event.metadata
        return controller, metadata

    def _execute_scene_specific_actions(self, controller, scene):
        """æ‰§è¡Œåœºæ™¯ç‰¹å®šçš„åˆå§‹åŒ–åŠ¨ä½œ"""
        if scene in self.scene_configs:
            for action_config in self.scene_configs[scene]:
                action = action_config["action"]
                if "moveMagnitude" in action_config:
                    controller.step(action=action, moveMagnitude=action_config["moveMagnitude"])
                elif "degrees" in action_config:
                    controller.step(action=action, degrees=action_config["degrees"])

    def run_initial_scene(self, scene_diagonal, origin_pos_path, scene, retry_limit=3):
        """è¿è¡Œåœºæ™¯åˆå§‹åŒ–ï¼Œæ”¯æŒè¶…æ—¶å’Œé‡è¯•"""
        controller = None
        metadata = None
        retry_count = 0

        def init_task():
            nonlocal controller
            nonlocal metadata
            controller, metadata = self.initialize_scene(scene_diagonal, origin_pos_path, scene) 
            
        init_thread = threading.Thread(target=init_task)
        init_thread.start()
        init_thread.join(self.timeout) 

        if init_thread.is_alive():
            print(f"Initialization exceeded {self.timeout} seconds, retrying...")
            retry_count += 1
            controller, metadata = self.initialize_scene(scene_diagonal, origin_pos_path, scene)
            return controller, metadata
        else:
            print("Initialization succeeded") 
            return controller, metadata

    def load_scene_metadata(self, metadata_path):
        """åŠ è½½åœºæ™¯å…ƒæ•°æ®"""
        metadata = load_json(metadata_path)
        return metadata[0] if metadata else None

    def load_scene_tasks(self, generate_task):
        """åŠ è½½åœºæ™¯ä»»åŠ¡"""
        tasks = load_json(generate_task)
        return tasks[0] if tasks else []


class TaskPlanner:
    def __init__(self, model, config=None):
        self.model = model
        self.config = config or PROMPT_CONFIG

    def plan_high_level_subgoals(self, taskname, environment_description, memory_text=None):
        """
        è°ƒç”¨ high_level_task_planning promptï¼Œè¾“å‡ºé«˜å±‚å­ç›®æ ‡ <SubgoalN> æ ‡ç­¾
        """
        systext = self.config["high_level_task_planning"]["systext"]
        history_info = ""
        if memory_text:
            history_info = f"History:\n{memory_text}\n"
        usertext = self.config["high_level_task_planning"]["usertext"].format(
            history_info=history_info,
            taskname=taskname,
            environment_description=environment_description
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        # è§£æ <SubgoalN> æ ‡ç­¾ï¼Œæ”¯æŒâ€œå­ç›®æ ‡: æè¿°â€æ ¼å¼
        import re
        subgoal_pattern = r'<Subgoal\d+>(.*?)</Subgoal\d+>'
        matches = re.findall(subgoal_pattern, result, re.DOTALL)
        subgoals = [m.strip() for m in matches]
        return subgoals

    def plan_executable_subtasks(self, subgoal, context=None):
        """
        è°ƒç”¨ executable_task_planning promptï¼Œå°†é«˜å±‚å­ç›®æ ‡ç»†åŒ–ä¸ºå¯æ‰§è¡ŒåŠ¨ä½œåºåˆ— <SubtaskN> æ ‡ç­¾
        """
        systext = self.config["executable_task_planning"]["systext"]
        usertext = self.config["executable_task_planning"]["usertext"].format(
            subgoal=subgoal,
            context=context or ""
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        # è§£æ <SubtaskN> æ ‡ç­¾
        import re
        subtask_pattern = r'<Subtask(\d+)>\s*\[(.*?)\]\s*\[(.*?)\]\s*</Subtask\1>'
        matches = re.findall(subtask_pattern, result, re.DOTALL)
        subtasks = []
        for match in matches:
            subtask_num, action, objtype = match
            subtasks.append({
                "subtask_id": int(subtask_num),
                "action": action.strip(),
                "objectId": "",
                "objectType": objtype.strip()
            })
        return subtasks


    def _parse_subtasks(self, planning_result):
        import re
        subtask_pattern = r'<Subtask(\d+)>\s*(.*?)\s*</Subtask\1>'
        matches = re.findall(subtask_pattern, planning_result, re.DOTALL)
        subtasks = []
        for match in matches:
            subtask_num, action_description = match
            # æå– [action] [object] æ ¼å¼
            action_type = ""
            object_type = ""
            action_obj_pattern = r'\[(.*?)\]\s*\[(.*?)\]'
            m = re.search(action_obj_pattern, action_description)
            if m:
                action_type = m.group(1).strip()
                object_type = m.group(2).strip()
            else:
                # å…¼å®¹åªå†™äº† action æˆ–æ ¼å¼ä¸æ ‡å‡†çš„æƒ…å†µ
                action_type = action_description.strip()
            subtasks.append({
                "subtask_id": int(subtask_num),
                "action": action_type,
                "objectId": "",
                "objectType": object_type
            })
        return subtasks

    def replan_based_on_user_response(self, taskname, observation, user_response, memory_text=None, navigable_list=None):
        """
        æ ¹æ®ç”¨æˆ·å›ç­”ç”Ÿæˆæ–°çš„planï¼ˆsubgoalsæˆ–subtasksï¼‰ã€‚
        """
        prompt_cfg = self.config.get("replan_by_user_response")
        systext = prompt_cfg["systext"]
        usertext = prompt_cfg["usertext"]
        navigable_str = ""
        if navigable_list:
            types = list(set([item["objectType"] for item in navigable_list]))
            navigable_str = ", ".join(types)
        usertext = usertext.format(
            taskname=taskname,
            observation=observation or "",
            user_response=user_response or "",
            memory_text=memory_text or "",
            navigable_str=navigable_str
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        # å¤ç”¨é«˜å±‚subgoalçš„æ­£åˆ™è§£æ
        import re
        subgoal_pattern = r'<Subgoal\d+>(.*?)</Subgoal\d+>'
        matches = re.findall(subgoal_pattern, result, re.DOTALL)
        subgoals = [m.strip() for m in matches]
        return subgoals


class ObservationGenerator:
    def __init__(self, model, config=None):
        self.model = model
        self.config = config or PROMPT_CONFIG

    def generate_observation(self, image_path, navigable_list=None):
        # å€Ÿé‰´ o1StyleGenerateï¼ŒObservation åªéœ€ç®€è¦æè¿°å¯è§ç‰©ä½“ï¼Œä¸éœ€è¦ç‰©ä½“å…³ç³»ï¼Œè¾“å‡º <Observation>...</Observation>
        # è·å–å¯è§ç±»åˆ«
        navigable_categories = []
        if navigable_list:
            navigable_categories = list(set([item["objectType"] for item in navigable_list]))
        systext = self.config["observation"]["systext"]
        usertext = self.config["observation"].get("usertext", "").format(navigable_categories=navigable_categories)
        llmapi = VLMAPI(self.model)
        observation = llmapi.vlm_request(systext, usertext, image_path)
        return observation

class QuestionGenerator:
    def __init__(self, model, config=None):
        self.model = model
        self.config = config or PROMPT_CONFIG

    def generate_general_question_for_plan(self, taskname, subgoals, observation=None):
        """
        é’ˆå¯¹åˆå§‹ä»»åŠ¡è§„åˆ’ï¼ˆsubgoalsï¼‰å’Œobservationï¼Œè‡ªåŠ¨æå‡ºä¸€ä¸ªgeneralç±»å‹çš„é—®é¢˜ã€‚
        """
        prompt_cfg = self.config.get("general_plan_question")
        systext = prompt_cfg["systext"]
        usertext = prompt_cfg["usertext"]
        subgoals_str = "\n".join([f"- {g}" for g in subgoals])
        usertext = usertext.format(taskname=taskname, subgoals=subgoals_str, observation=observation or "")
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        import re
        m = re.search(r'QUESTION:\s*(.*)', result)
        question = m.group(1).strip() if m else result.strip()
        return question

    def should_ask_question_vlm(self, taskname, observation=None, planning=None, memory_text=None, navigable_list=None, error_message=None):
        """
        ç”±VLMåˆ¤æ–­æ˜¯å¦éœ€è¦æé—®ï¼Œå¹¶è¿”å›(should_ask, type, question)
        """
        import re
        prompt_cfg = self.config["question_judge"]
        systext = prompt_cfg["systext"]
        # ç›´æ¥å°†å˜é‡æ˜¾å¼è¾“å…¥
        navigable_str = ""
        if navigable_list:
            types = list(set([item["objectType"] for item in navigable_list]))
            navigable_str = ", ".join(types)
        usertext = prompt_cfg["usertext"].format(
            taskname=taskname,
            observation=observation or "",
            planning=planning or "",
            memory_text=memory_text or "",
            navigable_str=navigable_str,
            error_message=error_message or ""
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        ask = re.search(r'ASK:\s*(yes|no)', result, re.IGNORECASE)
        qtype = re.search(r'TYPE:\s*(clarification|help|general)', result, re.IGNORECASE)
        question = re.search(r'QUESTION:\s*(.*)', result)
        should_ask = ask and ask.group(1).strip().lower() == "yes"
        question_type = qtype.group(1).strip().lower() if qtype else "general"
        question_text = question.group(1).strip() if question else ""
        return should_ask, question_type, question_text


class UserResponseHandler:
    def __init__(self, model, taskname, plan, memory, config=None):
        self.model = model
        self.taskname = taskname
        self.plan = plan
        self.memory = memory
        self.config = config or PROMPT_CONFIG

    def init_response(self, user_response):
        """
        ç»¼åˆå½“å‰taskã€è§„åˆ’ã€é—®ç­”å†å²å’Œç”¨æˆ·å›ç­”ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦replanã€‚
        è¿”å› (need_replan: bool, reason: str)
        """
        # è¿™é‡Œå¯ä»¥ç”¨LLMåˆ¤æ–­ï¼Œä¹Ÿå¯ä»¥ç”¨è§„åˆ™ã€‚å…ˆç»™å‡ºLLM promptæ–¹æ¡ˆï¼š
        prompt_cfg = self.config.get("user_response_replan_judge")
        systext = prompt_cfg["systext"]
        usertext = prompt_cfg["usertext"]

        plan_str = "\n".join([str(p) for p in self.plan]) if isinstance(self.plan, list) else str(self.plan)
        memory_str = "\n".join([m["content"] if isinstance(m, dict) and "content" in m else str(m) for m in self.memory]) if isinstance(self.memory, list) else str(self.memory)
        usertext = usertext.format(
            taskname=self.taskname,
            plan=plan_str,
            memory=memory_str,
            user_response=user_response
        )
        llmapi = VLMAPI(self.model)
        result = llmapi.vlm_request(systext, usertext)
        import re
        m = re.search(r'REPLAN:\s*(yes|no)', result, re.IGNORECASE)
        reason_m = re.search(r'REASON:\s*(.*)', result)
        need_replan = m and m.group(1).strip().lower() == "yes"
        reason = reason_m.group(1).strip() if reason_m else result.strip()
        return need_replan, reason

    def get_user_response(self, question):
        """æ¨¡æ‹Ÿæˆ–å®é™…è·å–ç”¨æˆ·å›ç­”ã€‚å®é™…éƒ¨ç½²æ—¶å¯æ›¿æ¢ä¸ºinput()æˆ–UIäº¤äº’ã€‚"""
        user_response = input("ğŸ˜ï¼šè¯·è¾“å…¥ä½ çš„å›ç­”ï¼š")
        # è¿™é‡Œå¯æ›¿æ¢ä¸ºå®é™…äº¤äº’
        return user_response


class RobotController:
    def __init__(self, controller, metadata, model, origin_path, config=None):
        self.memory = []  # é•¿æœŸè®°å¿†
        self.controller = controller
        self.metadata = metadata
        self.model = model
        self.origin_path = origin_path
        self.observation_generator = ObservationGenerator(model, config)
        self.task_planner = TaskPlanner(model, config)
        self.question_generator = QuestionGenerator(model, config)
        self.user_response_handler = UserResponseHandler(model, None, None, self.memory, config)
        # æ·»åŠ navigable_listç›¸å…³å±æ€§
        self.navigable_list = []
        self.round = 1
        self.his_objects_list = []
        # æ·»åŠ æé—®ç›¸å…³å±æ€§
        self.failed_attempts = 0
        self.last_question = None
        self.user_responses = []
        # æ–°å¢ï¼šç»Ÿä¸€å†å²è®°å½•å­—å…¸
        self.history = {
            "observation": [],
            "planning": [],
            "qa": []
        }


    def add_memory(self, entry, memory_type):
        """
        å­˜å‚¨è®°å¿†å†…å®¹ï¼Œmemory_typeä¸ºç±»åˆ«ï¼ˆå¦‚'planning'ã€'question'ã€'answer'ç­‰ï¼‰ï¼Œentryä¸ºå†…å®¹ã€‚
        """
        self.memory.append({"type": memory_type, "content": entry})

    def get_memory_text(self, max_steps=10, type_filter=None):
        """
        è¿”å›æœ€è¿‘çš„max_stepsæ¡è®°å¿†å†…å®¹ï¼Œå¯é€‰æŒ‰typeè¿‡æ»¤ã€‚
        """
        if type_filter:
            filtered = [m["content"] for m in self.memory if m["type"] == type_filter]
            return "\n".join(filtered[-max_steps:])
        else:
            return "\n".join(m["content"] for m in self.memory[-max_steps:])

    def initial_navigable_list(self):
        """åˆå§‹åŒ–å¯å¯¼èˆªå¯¹è±¡åˆ—è¡¨"""
        self.metadata = self.controller.last_event.metadata
        list_obj = get_volume_distance_rate(self.metadata)
        for item in list_obj:
            if item["isnavigable"] and item["objectType"] != "Floor":
                objectType = item["objectType"]
                objectId = item["objectId"]
                visibleTimes = 1
                choseTimes = 0
                obj_navigable = {
                    "objectType": objectType,
                    "objectId": objectId,
                    "visibleTimes": visibleTimes,
                    "choseTimes": choseTimes
                }
                self.navigable_list.append(obj_navigable)
        return self.navigable_list

    def update_navigable_list_vtime(self):
        """æ›´æ–°å¯å¯¼èˆªå¯¹è±¡åˆ—è¡¨çš„å¯è§æ¬¡æ•°"""
        self.metadata = self.controller.last_event.metadata
        list_obj = get_volume_distance_rate(self.metadata)
        for item in list_obj:
            if item["isnavigable"]:
                found = False
                for last_item in self.navigable_list:
                    if last_item["objectId"] == item["objectId"]:
                        last_item["visibleTimes"] += 1
                        found = True
                        break
                    
                if not found:
                    new_item = {
                        "objectType": item["objectType"],
                        "objectId": item["objectId"],
                        "visibleTimes": 1,
                        "choseTimes": 0
                    }
                    self.navigable_list.append(new_item)
        return self.navigable_list

    def get_object_types_from_navigable_list(self):
        """ä»å¯å¯¼èˆªåˆ—è¡¨ä¸­è·å–å¯¹è±¡ç±»å‹"""
        object_types = [item['objectType'] for item in self.navigable_list]
        unique_object_types = list(set(object_types))
        return unique_object_types

    def update(self):
        """æ›´æ–°æ§åˆ¶å™¨çŠ¶æ€"""
        self.metadata = self.controller.last_event.metadata
        self.navigable_list = self.update_navigable_list_vtime()

    def save_initial_observation_image(self):
        event = self.controller.last_event
        init_image_path = f"{self.origin_path}/0_init_observe.png"
        os.makedirs(os.path.dirname(init_image_path), exist_ok=True)
        save_image(event, init_image_path)
        return init_image_path

    def generate_observation(self, image_path):
        # ä¼ é€’ navigable_list ä»¥ä¾¿ Observation åªæè¿°å¯å¯¼èˆªç±»åˆ«
        # åˆå§‹åŒ–å¯å¯¼èˆªåˆ—è¡¨
        self.navigable_list = self.initial_navigable_list()
        obs = self.observation_generator.generate_observation(image_path, self.navigable_list)
        # è®°å½• observation å†å²ï¼Œå¢åŠ  round
        self.history["observation"].append({"round": self.round, "content": obs})
        return obs

    def plan_high_level_task(self, taskname, environment_description, memory_text=None):
        """é¦–æ¬¡ä»»åŠ¡è§„åˆ’ï¼šå°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œä¸ä½¿ç”¨memory"""
        subtasks = self.task_planner.plan_high_level_subgoals(
            taskname, environment_description, memory_text=memory_text
        )
        self.add_memory(f"Initial Task Planning: {subtasks}", "planning")
        # è®°å½• planning å†å²ï¼Œå¢åŠ  round
        self.history["planning"].append({"round": self.round, "content": subtasks})
        return subtasks

    def plan_task(self, taskname, environment_description):
        """ä»»åŠ¡è§„åˆ’ï¼šå°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼Œå¹¶å°†memoryä½œä¸ºä¸Šä¸‹æ–‡"""
        memory_text = self.get_memory_text()
        subtasks = self.task_planner.init_plan_task(
            taskname, environment_description, navigable_list=self.navigable_list, memory_text=memory_text
        )
        self.add_memory(f"Task Planning: {subtasks}", "planning")
        # è®°å½• planning å†å²ï¼Œå¢åŠ  round
        self.history["planning"].append({"round": self.round, "content": subtasks})
        return subtasks

    def format_subtasks_as_tags(self, subtasks):
        """å°†subtasksåˆ—è¡¨æ ¼å¼åŒ–ä¸º <SubtaskN> æ ‡ç­¾å­—ç¬¦ä¸²"""
        tag_strs = []
        for sub in subtasks:
            tag_strs.append(f"<Subtask{sub['subtask_id']}> [{sub['action']}] [{sub['objectType']}] </Subtask{sub['subtask_id']}>\n")
        return "".join(tag_strs)

    def get_user_response(self, question):
        """æ¨¡æ‹Ÿæˆ–å®é™…è·å–ç”¨æˆ·å›ç­”ã€‚å®é™…éƒ¨ç½²æ—¶å¯æ›¿æ¢ä¸ºinput()æˆ–UIäº¤äº’ã€‚"""
        user_response = input("ğŸ˜ï¼šè¯·è¾“å…¥ä½ çš„å›ç­”ï¼š")
        # è¿™é‡Œå¯æ›¿æ¢ä¸ºå®é™…äº¤äº’
        return user_response

    def get_navigable_list(self):
        """è·å–å¯å¯¼èˆªåˆ—è¡¨"""
        return self.navigable_list

    def add_to_history(self, object_info):
        """æ·»åŠ å¯¹è±¡åˆ°å†å²åˆ—è¡¨"""
        self.his_objects_list.append(object_info)
        self.add_memory(f"History: {object_info}", "history")


    def receive_user_response(self, response):
        """æ¥æ”¶ç”¨æˆ·å›ç­”"""
        self.user_responses.append({
            "question": self.last_question,
            "response": response,
            "timestamp": time.time()
        })
        # è®°å½•é—®ç­”å†å²ï¼Œå¢åŠ  round
        self.history["qa"].append({"round": self.round, "question": self.last_question, "response": response, "type": "answer"})
        print(f"ğŸ‘¤ ç”¨æˆ·å›ç­”: {response}")
        self.add_memory(f"Robot Question: {self.last_question}. User Response: {response}.", "qa")

    def try_ask_question(self, taskname, observation, subtasks):
        # ç»„ç»‡ observation
        obs_str = observation if observation else ""
        # æ ¼å¼åŒ– subtasks ä¸ºå¤šè¡Œå¯è¯»æ–‡æœ¬
        planning_str = ""
        if isinstance(subtasks, list) and len(subtasks) > 0 and isinstance(subtasks[0], dict):
            if 'subgoal_id' in subtasks[0]:
                planning_str = "\n".join([f"Subgoal{sub['subgoal_id']}: {sub.get('subgoal','')} - {sub.get('description','')}" for sub in subtasks])
            elif 'subtask_id' in subtasks[0]:
                planning_str = "\n".join([f"Subtask{sub['subtask_id']}: {sub.get('action','')} - {sub.get('objectType','')}" for sub in subtasks])
            else:
                planning_str = str(subtasks)
        elif subtasks:
            planning_str = str(subtasks)
        memory_text = self.get_memory_text()
        should_ask, question_type, question = self.question_generator.should_ask_question_vlm(
            taskname=taskname,
            observation=obs_str,
            planning=planning_str,
            navigable_list=self.navigable_list
        )
        if should_ask:
            self.last_question = question
            self.add_memory(f"Question({question_type}): {question}", "question")
            # è®°å½•é—®ç­”å†å²ï¼Œå¢åŠ  round
            self.history["qa"].append({"round": self.round, "question": question, "type": question_type})
            print(f"\nğŸ¤– æœºå™¨äººæé—®({question_type}): {question}")
            return question
        return None

    def increment_failed_attempts(self):
        """å¢åŠ å¤±è´¥æ¬¡æ•°"""
        self.failed_attempts += 1
        self.add_memory(f"Failed attempt #{self.failed_attempts}", "failed_attempts")

    def reset_failed_attempts(self):
        """é‡ç½®å¤±è´¥æ¬¡æ•°"""
        self.failed_attempts = 0
        self.add_memory("Reset failed attempts", "failed_attempts")

    def get_question_history(self):
        """è·å–æé—®å†å²"""
        return self.user_responses

    def ask_general_question_for_plan(self, taskname, subgoals, observation=None):
        """
        é’ˆå¯¹åˆå§‹ä»»åŠ¡è§„åˆ’å’Œobservationï¼Œè‡ªåŠ¨æå‡ºgeneralç±»å‹çš„é—®é¢˜å¹¶å­˜å…¥memoryã€‚
        """
        question = self.question_generator.generate_general_question_for_plan(taskname, subgoals, observation=observation)
        self.last_question = question
        self.add_memory(f"General Question: {question}", "question")
        print(f"\nğŸ¤– æœºå™¨äººæå‡ºgeneralé—®é¢˜: {question}")
        return question

    def set_user_response_handler_context(self, taskname, plan):
        self.user_response_handler.taskname = taskname
        self.user_response_handler.plan = plan
        self.user_response_handler.memory = self.memory


if __name__=="__main__":
    env="taskgenerate"
    model = "qwen2.5vl:32b" # use gpt-4o to generate trajectories
    # you can set timeout for AI2THOR init here.        

    ###### step1. choose the task type here ####################
    tasktype="pickup_and_put"
    room_type = ['kitchens','living_rooms','bedrooms','bathrooms']
    room = 'kitchens'
    scene = 'FloorPlan3'
    
    # åˆ›å»ºåœºæ™¯ç®¡ç†å™¨
    scene_manager = SceneManager()
    
    # è·å–åœºæ™¯ç›¸å…³è·¯å¾„
    paths = scene_manager.get_scene_paths(env, room, scene, tasktype)
    metadata_path = paths['metadata_path']
    origin_pos_path = paths['origin_pos_path']
    generate_task = paths['generate_task']
    
    print("metadata_path:", metadata_path)
    print("task_metadata_path:", generate_task)
    
    # åŠ è½½åœºæ™¯å…ƒæ•°æ®å’Œä»»åŠ¡
    metadata = scene_manager.load_scene_metadata(metadata_path)
    tasks = scene_manager.load_scene_tasks(generate_task)

    for instruction_idx, task in enumerate(tasks, start=0):                                                            
        print("\n\n*********************************************************************")
        print(f"Scene:{scene} Task_Type: {tasktype} Processing_Task: {instruction_idx}")
        print("*********************************************************************\n")

        task=tasks[instruction_idx]
        print("task:",task)
        
        start_time = time.time()
        origin_path=f"data/data_{task['tasktype']}/{scene}_{task['tasktype']}_{instruction_idx}"
        
        # è®¡ç®—åœºæ™¯å¯¹è§’çº¿è·ç¦»
        scene_diagonal = scene_manager.calculate_scene_diagonal(metadata)
        
        max_retries=2
        error_paths = []  
        for attempt in range(max_retries + 1): 
            try:
                # ä½¿ç”¨åœºæ™¯ç®¡ç†å™¨åˆå§‹åŒ–åœºæ™¯
                controller, metadata = scene_manager.run_initial_scene(scene_diagonal, origin_pos_path, scene)

                # å°è£…åçš„æœºå™¨äººæ§åˆ¶å™¨
                robot_controller = RobotController(controller, metadata, model, origin_path)
                
                # æ­¥éª¤1ï¼šä¿å­˜åˆå§‹è§‚å¯Ÿå›¾ç‰‡
                init_image_path = robot_controller.save_initial_observation_image()
                
                # æ­¥éª¤2ï¼šç”Ÿæˆobservation
                observation = robot_controller.generate_observation(init_image_path)
                print("[Observation]", observation)
                
                # æ­¥éª¤3ï¼šä»»åŠ¡è§„åˆ’ï¼ˆåªç”¨é«˜å±‚tasknameå’Œobservationï¼‰
                taskname = task["taskname"]  # ä¾‹å¦‚ "æŠŠè‹¹æœæ”¾è¿›å†°ç®±"
                subtasks = robot_controller.plan_high_level_task(taskname, observation)
                print("[Initial Task Planning]", subtasks)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æé—®
                question = robot_controller.ask_general_question_for_plan(taskname, subtasks)
                
                if question:
                    robot_controller.set_user_response_handler_context(taskname, subtasks)
                    # è·å–ç”¨æˆ·å›ç­”
                    user_response = robot_controller.user_response_handler.get_user_response(question)
                    robot_controller.receive_user_response(user_response)

                    print("[Re-planning based on user response]")
                    # å…ˆåˆ¤æ–­æ˜¯å¦éœ€è¦replan
                    need_replan, reason = robot_controller.user_response_handler.init_response(user_response)
                    if need_replan:
                        new_subtasks = robot_controller.task_planner.replan_based_on_user_response(
                            taskname, observation, user_response, robot_controller.get_memory_text(), robot_controller.navigable_list
                        )
                        print("[Re-planned Task]", new_subtasks)
                        robot_controller.add_memory(f"Re-planned Task: {new_subtasks}", "planning")
                        # ä½ å¯ä»¥åœ¨æ­¤å¤„ç»§ç»­åç»­æ‰§è¡Œæ–°è§„åˆ’çš„é€»è¾‘
                    else:
                        print(f"æ— éœ€replanï¼ŒåŸå› ï¼š{reason}")

                # æ­¥éª¤4ï¼šè·å–å¯å¯¼èˆªå¯¹è±¡ç±»å‹ï¼ˆç”¨äºåç»­è§„åˆ’ï¼‰
                navigable_types = robot_controller.get_object_types_from_navigable_list()
                print("[Navigable Types]", navigable_types)
                
                # æ­¥éª¤5ï¼šæ›´æ–°å¯å¯¼èˆªåˆ—è¡¨
                robot_controller.update()
                updated_navigable_list = robot_controller.get_navigable_list()
                print("[Updated Navigable List]", len(updated_navigable_list), "objects")
                
                # åç»­æ­¥éª¤ï¼šå¾ªç¯æ‰§è¡Œå­ä»»åŠ¡
                # for subtask in subtasks:
                #     print("æ‰§è¡Œå­ä»»åŠ¡:", subtask)
                #     # è¿™é‡Œå¯ä»¥æ ¹æ®subtask["action"]å’Œ["objectType"]ç­‰ï¼Œè°ƒç”¨åº•å±‚æ§åˆ¶API
                #     # æ¯æ­¥å¯è§‚æµ‹ã€å¯replan
                #     # ä¼ªä»£ç ï¼š
                #     # result = robot_controller.execute_subtask(subtask)
                #     # if result == "need_replan":
                #     #     observation = robot_controller.generate_observation(...)
                #     #     subtasks = robot_controller.plan_task(taskname, observation)
                #     #     break
                
                # o1stylegenerate=O1StyleGenerate(
                #     controller,scene,origin_path,metadata,task,model=model
                # )
                # o1stylegenerate.initial_navigable_list()
                
                # # json_path=f"{origin_path}/metadata/0_metadata.json"
                # # o1stylegenerate.generate_o1style_data["round_metadata"].append(json_path)
                # # save_data_to_json(o1stylegenerate.metadata,json_path)
                # # o1stylegenerate.generate_o1style_data["round_navigable_list"].append(o1stylegenerate.navigable_list)

                
                # o1stylegenerate.generate_o1style_data["task_metadata"]=task
                
                # o1stylegenerate.generate_o1style_data["scene"]=scene
                # o1stylegenerate.generate_o1style_data["tasktype"]=tasktype 
                # o1stylegenerate.generate_o1style_data["instruction_idx"]=instruction_idx
                
                # o1stylegenerate.generate_one_o1style_data(plan_num,correct_num)
                
                # end_time = time.time()

                # execution_time = end_time - start_time
                # print(f"Execution time: {execution_time:.4f} seconds") 
                
                # o1stylegenerate.generate_o1style_data["time"]=execution_time

                # path=f"{origin_path}/{scene}_{task['tasktype']}_{instruction_idx}_{trajectory_idx}.json"
                
                # save_data_to_json(o1stylegenerate.generate_o1style_data,path)
                # print("generate_o1style_data save:",{path})
                
                # controller.stop()
                # break

            except Exception as e:
                print(f"Error:{e},try again.")
                clear_folder(origin_path)
            
                if attempt == max_retries - 1: 
                    print(f"Retry {max_retries} times, jump the task.")
                    error_paths.append(origin_path)  
                    save_data_to_json(error_paths,"./wrong_generte_path_list.json")
                    continue
